{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNOYEl9tkLF9E4fSISjZZgP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/robbiedantonio/Img2LaTeX/blob/main/Img2LaTeX.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Img2LaTeX Project\n",
        "#### Using deep learning techniques to get LaTeX code strings from a typed (PDF) image of a mathematical expression"
      ],
      "metadata": {
        "id": "gOQy4KnYrHmo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Loading data and implementing token dictionary**"
      ],
      "metadata": {
        "id": "vLBLiVjzrZLE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ANtba3rPf-5Z",
        "outputId": "fb49cd36-8394-464e-b938-55f6c9ed8aae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "'''\n",
        "Mount Google Drive, copy data to local runtime, and unzip folders\n",
        "'''\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "! cp /content/drive/MyDrive/'Img2LaTeX_data'/train.zip /content\n",
        "! cp /content/drive/MyDrive/'Img2LaTeX_data'/test.zip /content\n",
        "! cp /content/drive/MyDrive/'Img2LaTeX_data'/val.zip /content\n",
        "! cp /content/drive/'MyDrive'/'Img2LaTeX_data'/math.txt /content\n",
        "\n",
        "! unzip -DD -q  ./train.zip -d  .\n",
        "! unzip -DD -q  ./test.zip -d  .\n",
        "! unzip -DD -q  ./val.zip -d  ."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Length of datasets\n",
        "'''\n",
        "num_train_str = !ls train | wc -l\n",
        "num_test_str = !ls test | wc -l\n",
        "num_val_str = !ls val | wc -l\n",
        "num_train = int(num_train_str[0])\n",
        "num_test = int(num_test_str[0])\n",
        "num_val = int(num_val_str[0])\n",
        "\n",
        "print(f'Number of train images: {num_train}\\nNumber of test images: {num_test}\\nNumber of validation images: {num_val}\\nTotal images: {num_train+num_test+num_val}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "84ZemY2giCOa",
        "outputId": "79d7db69-9fe1-4259-cfb3-5edb4f4b4bc9"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of train images: 158480\n",
            "Number of test images: 30637\n",
            "Number of validation images: 6765\n",
            "Total images: 195882\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Paths to folders\n",
        "'''\n",
        "train_root = \"./train/\"\n",
        "test_root = \"./test/\"\n",
        "val_root = \"./val/\"\n",
        "labels = \"./math.txt\""
      ],
      "metadata": {
        "id": "2ONjSonziFJq"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Load data and preprocess images\n",
        "'''\n",
        "import os\n",
        "import torch.utils.data\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "class LatexDataset(torch.utils.data.Dataset):\n",
        "  def __init__(self, transform=None, dataroot=None, labels=None, max_seq_length=256):\n",
        "        '''\n",
        "        Initialize the dataset\n",
        "            transform: A torchvision transform to apply to the images\n",
        "            dataroot: The root directory of the dataset\n",
        "            max_seq_length: The maximum length of a sequence. This allows us\n",
        "                to simplify training by avoiding sequences that are too long.\n",
        "        '''\n",
        "        assert dataroot is not None and labels is not None          # Make sure dataroot and labels are specified\n",
        "        assert os.path.exists(dataroot) and os.path.exists(labels)  # Make sure dataroot and labels exist\n",
        "        assert max_seq_length > 0                                   # Make sure max_seq_length is positive\n",
        "\n",
        "        self.transform = transform\n",
        "        self.dataroot = dataroot\n",
        "        self.labels_txt = labels\n",
        "        self.max_seq_length = max_seq_length\n",
        "        self._parse()\n",
        "\n",
        "  def __parse__(self):\n",
        "        '''\n",
        "        Parse the math.txt file.\n",
        "        Populates the following private variables:\n",
        "            self.im_paths: A list of strings storing the associated image paths\n",
        "            self.labels: A list of strings, where each string is the latex code for an image\n",
        "        '''\n",
        "        def getImPath(idx):\n",
        "            # Find image in either train, test, or validation folder\n",
        "            imname = str(idx - 1).zfill(7) + '.png'\n",
        "            if os.path.exists(f'{self.dataroot}{imname}'):\n",
        "              impath = f'{self.dataroot}{imname}'\n",
        "            else:\n",
        "              return None\n",
        "\n",
        "            try:\n",
        "                Image.open(impath).verify()\n",
        "            except Exception as e:\n",
        "                # Some images can't be opened\n",
        "                # print(f\"Image at path {impath} is corrupted. Error: {e}\")\n",
        "                return None\n",
        "\n",
        "            return impath\n",
        "\n",
        "        self.im_paths = []\n",
        "        self.labels = []\n",
        "\n",
        "        with open(self.labels_txt) as f:\n",
        "            for idx, line in enumerate(f):\n",
        "                impath = getImPath(idx+1)\n",
        "\n",
        "                if impath is not None:\n",
        "                    labels = line.strip('\\n')\n",
        "                    if len(labels) < self.max_seq_length-1: # Loading images with certain latex length\n",
        "                      self.im_paths.append(impath)          # Image name\n",
        "                      self.labels.append(labels)            # String of latex code\n",
        "\n",
        "  def __len__(self):\n",
        "        '''\n",
        "        Return length of the dataset.\n",
        "        '''\n",
        "        assert len(self.labels) == len(self.im_paths)\n",
        "        return len(self.labels)\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "        '''\n",
        "        Get a single sample from the dataset.\n",
        "        Returns a single (image, attributes) tuple.\n",
        "        '''\n",
        "        def img_load(index):\n",
        "            img = Image.open(self.im_paths[index])\n",
        "            # imgray = imraw.convert('L')                         # Convert image to greyscale\n",
        "            # imthresh = imgray.point(lambda p: p > 240 and 255)  # Threshold image to remove background (white)\n",
        "            if self.transform is not None:\n",
        "              return self.transform(img)\n",
        "            else:\n",
        "              return img\n",
        "\n",
        "        target = self.labels[index]\n",
        "        return img_load(index), target"
      ],
      "metadata": {
        "id": "5eoenWiQiQZs"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Dictionary block: converts a LaTeX string to a dictionary of latex tokens, where\n",
        "each unique token has its own entry and integer value assigned to it\n",
        "'''\n",
        "\n",
        "class LatexDict():\n",
        "    def __init__(self, label_file=None, max_seq_length=256):\n",
        "        assert label_file is not None                       # Make sure label_file is specified\n",
        "        self.labels_txt = label_file\n",
        "        self.max_seq_length = max_seq_length\n",
        "        self.latex_dict = {'<UKN>':0, '<PAD>':1, '<EOS>':2}            # Initialize with token for unknown, pad, and end of sequence\n",
        "        self.latex_dict_inverse = {0:'<UKN>', 1:'<PAD>', 2:'<EOS>'}    # Initialize reverse dict for quicker reverse lookups\n",
        "        self.create_dict()\n",
        "\n",
        "    def create_dict(self):\n",
        "        '''\n",
        "        Go through entire label file and populate normal and reverse dictionary\n",
        "        '''\n",
        "        with open(self.labels_txt) as f:\n",
        "            for line in f:\n",
        "                tokens = line.split()\n",
        "                for token in tokens:\n",
        "                    if token not in self.latex_dict:\n",
        "                        # Assign a new ID for the unseen token\n",
        "                        new_id = len(self.latex_dict)\n",
        "                        self.latex_dict[token] = new_id\n",
        "                        self.latex_dict_inverse[new_id] = token\n",
        "\n",
        "    def map_tokens(self, latex_strings_list, batch_size):\n",
        "        '''\n",
        "        Map a list of LaTeX strings to a tensor of integers using the dictionary\n",
        "        latex_string_list: A list of LaTeX strings\n",
        "        batch_size: Number of samples in the batch\n",
        "\n",
        "        Returns:\n",
        "            ids_tensor: A tensor of integers with shape (batch_size, max_seq_length)\n",
        "        '''\n",
        "        ids_tensor = torch.full((batch_size, self.max_seq_length), self.latex_dict['<PAD>'], dtype=torch.float32)\n",
        "\n",
        "        for row, tex_str in enumerate(latex_strings_list):\n",
        "            tex_str = r'{ ' + tex_str + ' }'\n",
        "            tokens = tex_str.split()\n",
        "            for col, token in enumerate(tokens):\n",
        "                ids_tensor[row, col] = self.latex_dict[token]\n",
        "\n",
        "        return ids_tensor\n",
        "\n",
        "    def tokens_to_tex(self, token_vec):\n",
        "        '''\n",
        "        Maps a 1D tensor of integers to a LaTeX string\n",
        "        token_vec: A tensor of integers of length max_seq_length\n",
        "\n",
        "        Returns:\n",
        "            tex_str: A string of LaTeX code corresponding to the token vector\n",
        "        '''\n",
        "        tex_str = ' '\n",
        "        for token_id in token_vec.tolist():\n",
        "            if token_id in self.latex_dict_inverse:\n",
        "                if self.latex_dict_inverse[token_id] == '<EOS>':\n",
        "                    break\n",
        "                if self.latex_dict_inverse[token_id] != '<PAD>' and self.latex_dict_inverse[token_id] != '<UKN>':\n",
        "                    tex_str += self.latex_dict_inverse[token_id] + ' '\n",
        "\n",
        "        return tex_str\n",
        "\n",
        "    def __dict__(self):\n",
        "        return self.latex_dict\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.latex_dict)"
      ],
      "metadata": {
        "id": "D9iXDOIDkCQO"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Implementing Model:**\n",
        "\n",
        "Current design idea:\n",
        "\n",
        "Image -> Preprocess (transforms) -> CNN encoder + sinusoidal positional encoding -> transformer decoder -> Cross-entropy loss"
      ],
      "metadata": {
        "id": "7krY09EVrlEV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn"
      ],
      "metadata": {
        "id": "0xI5OQuVtJKf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "CNN Encoder Class\n",
        "'''\n",
        "class CNNEncoder(nn.Module):\n",
        "    def __init__(self, input_channels, output_channels, kernel_sizes, strides, paddings):\n",
        "        '''\n",
        "        Initialize the CNN encoder\n",
        "\n",
        "        input_channels: Number of input channels\n",
        "        output_channels: Number of output channels\n",
        "        kernel_sizes: List of kernel sizes\n",
        "        strides: List of strides\n",
        "        paddings: List of paddings\n",
        "        '''\n",
        "        super(CNNEncoder, self).__init__()\n",
        "\n",
        "        self.conv_layers = nn.ModuleList()\n",
        "        self.pool_layers = nn.ModuleList()\n",
        "        self.norm_layers = nn.ModuleList()\n",
        "\n",
        "        for i in range(len(kernel_sizes)):\n",
        "            in_channels = input_channels if i == 0 else output_channels[i-1]\n",
        "            out_channels = output_channels[i]\n",
        "            kernel_size = kernel_sizes[i]\n",
        "            stride = strides[i]\n",
        "            padding = paddings[i]\n",
        "\n",
        "            conv_layer = nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding)\n",
        "            pool_layer = nn.MaxPool2d(2, 2)\n",
        "            norm_layer = nn.BatchNorm2d(out_channels)\n",
        "\n",
        "            self.conv_layers.append(conv_layer)\n",
        "            self.pool_layers.append(pool_layer)\n",
        "            self.norm_layers.append(norm_layer)\n",
        "\n",
        "    def forward(self, x):\n",
        "        '''\n",
        "        Forward pass of the CNN encoder\n",
        "        x: Input tensor of shape (batch_size, input_channels, height, width)\n",
        "\n",
        "        Returns:\n",
        "            features: A list of tensors, where each tensor represents the feature maps\n",
        "                from one convolutional layer, of shape:\n",
        "                (batch_size, output_channels[i], layer_output_height[i], layer_output_width[i]),\n",
        "                where i is the index of the corresponding convolutional layer.\n",
        "        '''\n",
        "\n",
        "        features = []\n",
        "        for conv, pool, norm in zip(self.conv_layers, self.pool_layers, self.norm_layers):\n",
        "            x = conv(x)\n",
        "            x = pool(x)\n",
        "            x = norm(x)\n",
        "            features.append(x)\n",
        "\n",
        "        return features"
      ],
      "metadata": {
        "id": "2W2okICDsdbU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}